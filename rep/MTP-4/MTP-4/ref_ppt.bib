@InProceedings{10.1007/978-3-319-60964-5_44,
author="Dong, Hao
and Yang, Guang
and Liu, Fangde
and Mo, Yuanhan
and Guo, Yike",
editor="Vald{\'e}s Hern{\'a}ndez, Mar{\'i}a
and Gonz{\'a}lez-Castro, V{\'i}ctor",
title="Automatic Brain Tumor Detection and Segmentation Using U-Net Based Fully Convolutional Networks",
booktitle="Medical Image Understanding and Analysis",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="506--517",
abstract="A major challenge in brain tumor treatment planning and quantitative evaluation is determination of the tumor extent. The noninvasive magnetic resonance imaging (MRI) technique has emerged as a front-line diagnostic tool for brain tumors without ionizing radiation. Manual segmentation of brain tumor extent from 3D MRI volumes is a very time-consuming task and the performance is highly relied on operator's experience. In this context, a reliable fully automatic segmentation method for the brain tumor segmentation is necessary for an efficient measurement of the tumor extent. In this study, we propose a fully automatic method for brain tumor segmentation, which is developed using U-Net based deep convolutional networks. Our method was evaluated on Multimodal Brain Tumor Image Segmentation (BRATS 2015) datasets, which contain 220 high-grade brain tumor and 54 low-grade tumor cases. Cross-validation has shown that our method can obtain promising segmentation efficiently.",
isbn="978-3-319-60964-5"
}


@article{Milletari2016VNetFC,
  title={V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation},
  author={Fausto Milletari and Nassir Navab and Seyed-Ahmad Ahmadi},
  journal={2016 Fourth International Conference on 3D Vision (3DV)},
  year={2016},
  pages={565-571}
}

@article{SHEHAB2021404,
title = {An efficient brain tumor image segmentation based on deep residual networks (ResNets)},
journal = {Journal of King Saud University - Engineering Sciences},
volume = {33},
number = {6},
pages = {404-412},
year = {2021},
issn = {1018-3639},
doi = {https://doi.org/10.1016/j.jksues.2020.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S1018363920302506},
author = {Lamia H. Shehab and Omar M. Fahmy and Safa M. Gasser and Mohamed S. El-Mahallawy},
keywords = {Brain tumor segmentation, Magnetic Resonance Imaging (MRI), Deep Neural Networks (DNN), Deep Residual Learning Network (ResNet)},
abstract = {Automatic segmentation of brain tumor from Magnetic Resonance Images (MRI) is one of the challenging tasks in computer vision. Many proposals investigate the use of Deep Neural Networks (DNN) in image segmentation as they have a high performance in automatic segmentation of brain tumors images. Due to the gradient diffusion problem and complexity, it generally takes a lot of time and extra computational power for training deeper neural networks. In this paper, we present an automatic technique for brain tumor segmentation depending on Deep Residual Learning Network (ResNet) to get over the gradient problem of DNN. ResNets accomplish more accuracy and can make the training process faster compared to their equivalent DNN. To achieve this enhancement, ResNets add a shortcut skip connection parallel to convolutional neural networks layers. Simulation examples have been carried out on dataset BRATS 2015 to verify the superiority of the proposed technique. Results verify that the proposed technique has an improved accuracy of 83\%, 90\%, and 85\% for the complete, core, and enhancing regions, respectively. Moreover, it has an average computation time (3 times) faster than other DNN techniques.}
}

@INPROCEEDINGS{7780459,
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Deep Residual Learning for Image Recognition}, 
  year={2016},
  volume={},
  number={},
  pages={770-778},
  doi={10.1109/CVPR.2016.90}}
  
  @article{MAJI2022103077,
title = {Attention Res-UNet with Guided Decoder for semantic segmentation of brain tumors},
journal = {Biomedical Signal Processing and Control},
volume = {71},
pages = {103077},
year = {2022},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2021.103077},
url = {https://www.sciencedirect.com/science/article/pii/S1746809421006741},
author = {Dhiraj Maji and Prarthana Sigedar and Munendra Singh},
keywords = {MRI, Brain tumor segmentation, Res-UNet, Attention gates, Guided decoder},
abstract = {The automatic segmentation of brain tumors in Magnetic Resonance Imaging (MRI) plays a major role in accurate diagnosis and treatment planning. The present study proposes a new deep learning generator architecture called Attention Res-UNet with Guided Decoder (ARU-GD) for the segmentation of brain tumors. The proposed generator architecture have the capability to explicitly guide the learning process of each decoder layer. The individual loss function to each decoder layer helps to supervise the learning process of each layer in the decoder and thereby enables them to generate better feature maps. The attention gates in the generator focuses on the activation of relevant information instead of allowing all information to pass through the skip connections in the Res-UNet. Our model performed well in comparison to the baseline models i.e. UNet, Res-UNet, and Res-UNet with attention gates. The proposed ARU-GD is compared with popular deep learning models VGG-Net, MobileNet, QuickNAT, DenseNet and XceptionNet, and BraTS 2019 leaderboard models. The proposed ARU-GD has achieved Dice Scores of 0.911, 0.876 and 0.801 and mean IoU of 0.838, 0.781 and 0.668 on the whole tumor, tumor core and enhancing tumor respectively on unseen High-Grade Glioma test data. The implementation code is available on the following Github link.}
}

@article{Oktay2018AttentionUL,
  title={Attention U-Net: Learning Where to Look for the Pancreas},
  author={Ozan Oktay and Jo Schlemper and Lo{\"i}c Le Folgoc and M. J. Lee and Mattias P. Heinrich and Kazunari Misawa and Kensaku Mori and Steven G. McDonagh and Nils Y. Hammerla and Bernhard Kainz and Ben Glocker and Daniel Rueckert},
  journal={ArXiv},
  year={2018},
  volume={abs/1804.03999}
}


@InProceedings{10.1007/978-3-319-24574-4_28,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}


@article{TAGHANAKI201924,
title = {Combo loss: Handling input and output imbalance in multi-organ segmentation},
journal = {Computerized Medical Imaging and Graphics},
volume = {75},
pages = {24-33},
year = {2019},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2019.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S0895611118305688},
author = {Saeid Asgari Taghanaki and Yefeng Zheng and S. {Kevin Zhou} and Bogdan Georgescu and Puneet Sharma and Daguang Xu and Dorin Comaniciu and Ghassan Hamarneh},
keywords = {Class-imbalance, Output imbalance, Deep convolutional neural networks, Loss function, Multi-organ segmentation},
abstract = {Simultaneous segmentation of multiple organs from different medical imaging modalities is a crucial task as it can be utilized for computer-aided diagnosis, computer-assisted surgery, and therapy planning. Thanks to the recent advances in deep learning, several deep neural networks for medical image segmentation have been introduced successfully for this purpose. In this paper, we focus on learning a deep multi-organ segmentation network that labels voxels. In particular, we examine the critical choice of a loss function in order to handle the notorious imbalance problem that plagues both the input and output of a learning model. The input imbalance refers to the class-imbalance in the input training samples (i.e., small foreground objects embedded in an abundance of background voxels, as well as organs of varying sizes). The output imbalance refers to the imbalance between the false positives and false negatives of the inference model. In order to tackle both types of imbalance during training and inference, we introduce a new curriculum learning based loss function. Specifically, we leverage Dice similarity coefficient to deter model parameters from being held at bad local minima and at the same time gradually learn better model parameters by penalizing for false positives/negatives using a cross entropy term. We evaluated the proposed loss function on three datasets: whole body positron emission tomography (PET) scans with 5 target organs, magnetic resonance imaging (MRI) prostate scans, and ultrasound echocardigraphy images with a single target organ i.e., left ventricular. We show that a simple network architecture with the proposed integrative loss function can outperform state-of-the-art methods and results of the competing methods can be improved when our proposed loss is used.}
}


@ARTICLE{8630007,
  author={Zhou, Xiao-Yun and Yang, Guang-Zhong},
  journal={IEEE Robotics and Automation Letters}, 
  title={Normalization in Training U-Net for 2-D Biomedical Semantic Segmentation}, 
  year={2019},
  volume={4},
  number={2},
  pages={1792-1799},
  doi={10.1109/LRA.2019.2896518}}


@ARTICLE{9446143,  author={Siddique, Nahian and Paheding, Sidike and Elkin, Colin P. and Devabhaktuni, Vijay},  journal={IEEE Access},   title={U-Net and Its Variants for Medical Image Segmentation: A Review of Theory and Applications},   year={2021},  volume={9},  number={},  pages={82031-82057},  doi={10.1109/ACCESS.2021.3086020}}

@ARTICLE{2021arXiv211003352F,
       author = {{Futrega}, Micha{\l} and {Milesi}, Alexandre and {Marcinkiewicz}, Michal and {Ribalta}, Pablo},
        title = "{Optimized U-Net for Brain Tumor Segmentation}",
      journal = {arXiv e-prints},
     keywords = {Electrical Engineering and Systems Science - Image and Video Processing, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
         year = 2021,
        month = oct,
          eid = {arXiv:2110.03352},
        pages = {arXiv:2110.03352},
archivePrefix = {arXiv},
       eprint = {2110.03352},
 primaryClass = {eess.IV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2021arXiv211003352F},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{9046011,  author={Zhang, Jianxin and Jiang, Zongkang and Dong, Jing and Hou, Yaqing and Liu, Bin},  journal={IEEE Access},   title={Attention Gate ResU-Net for Automatic MRI Brain Tumor Segmentation},   year={2020},  volume={8},  number={},  pages={58533-58545},  doi={10.1109/ACCESS.2020.2983075}}

@INPROCEEDINGS{8100166,
  author={Wang, Fei and Jiang, Mengqing and Qian, Chen and Yang, Shuo and Li, Cheng and Zhang, Honggang and Wang, Xiaogang and Tang, Xiaoou},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Residual Attention Network for Image Classification}, 
  year={2017},
  volume={},
  number={},
  pages={6450-6458},
  doi={10.1109/CVPR.2017.683}}
  
@INPROCEEDINGS{9277638,
  author={Jadon, Shruti},
  booktitle={2020 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)}, 
  title={A survey of loss functions for semantic segmentation}, 
  year={2020},
  volume={},
  number={},
  pages={1-7},
  doi={10.1109/CIBCB48159.2020.9277638}}


@article{https://doi.org/10.1049/iet-cvi.2014.0193,
author = {Anitha, V. and Murugavalli, S.},
title = {Brain tumour classification using two-tier classifier with adaptive segmentation technique},
journal = {IET Computer Vision},
volume = {10},
number = {1},
pages = {9-17},
keywords = {brain, tumours, biomedical MRI, medical image processing, image classification, image segmentation, self-organising feature maps, feature extraction, discrete wavelet transforms, image filtering, brain tumour classification, two-tier classifier, adaptive segmentation technique, tissue mass, anomalous cells, magnetic resonance imaging, brain MRI tumour detection, anatomical structures, abnormal tissues, brain tumour segmentation, adaptive pillar K-means algorithm, self-organising map neural network, feature extraction, discrete wavelet transform blend wavelets, filter factors, K-nearest neighbour},
doi = {https://doi.org/10.1049/iet-cvi.2014.0193},
url = {https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/iet-cvi.2014.0193},
eprint = {https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/iet-cvi.2014.0193},
abstract = {A brain tumour is a mass of tissue that is structured by a gradual addition of anomalous cells and it is important to classify brain tumours from the magnetic resonance imaging (MRI) for treatment. Human investigation is the routine technique for brain MRI tumour detection and tumours classification. Interpretation of images is based on organised and explicit classification of brain MRI and also various techniques have been proposed. Information identified with anatomical structures and potential abnormal tissues which are noteworthy to treat are given by brain tumour segmentation on MRI, the proposed system uses the adaptive pillar K-means algorithm for successful segmentation and the classification methodology is done by the two-tier classification approach. In the proposed system, at first the self-organising map neural network trains the features extracted from the discrete wavelet transform blend wavelets and the resultant filter factors are consequently trained by the K-nearest neighbour and the testing process is also accomplished in two stages. The proposed two-tier classification system classifies the brain tumours in double training process which gives preferable performance over the traditional classification method. The proposed system has been validated with the support of real data sets and the experimental results showed enhanced performance.},
year = {2016}
}